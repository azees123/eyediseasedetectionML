{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0202ac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2799e8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process images and prepare dataset\n",
    "def process_images(path, label, data_list, labels_list):\n",
    "    for img_file in os.listdir(path):\n",
    "        img = Image.open(os.path.join(path, img_file))\n",
    "        img = img.resize((64, 64))  # Resize the image\n",
    "        img = img.convert('RGB')  # Convert the image to RGB mode\n",
    "        img = np.array(img)  # Convert to NumPy array\n",
    "        data_list.append(img)  # Append image to data\n",
    "        labels_list.append(label)  # Append label to labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b98c39c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to hold all the images and labels\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "378a65fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all the paths and corresponding labels (0, 1, 2, ...)\n",
    "paths_and_labels = [\n",
    "    (r\"dataset\\AugmentedDataset\\CentralSerousChorioretinopathy\", 0),\n",
    "    (r\"dataset\\AugmentedDataset\\DiabeticRetinopathy\", 1),\n",
    "    (r\"dataset\\AugmentedDataset\\DiscEdema\", 2),\n",
    "    (r\"dataset\\AugmentedDataset\\Glaucoma\", 3),\n",
    "    (r\"dataset\\AugmentedDataset\\Healthy\", 4),\n",
    "    (r\"dataset\\AugmentedDataset\\MacularScar\", 5),\n",
    "    (r\"dataset\\AugmentedDataset\\Myopia\", 6),\n",
    "    (r\"dataset\\AugmentedDataset\\Pterygium\", 7),\n",
    "    (r\"dataset\\AugmentedDataset\\RetinalDetachment\", 8),\n",
    "    (r\"dataset\\AugmentedDataset\\RetinitisPigmentosa\", 9)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ca428c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels from each folder\n",
    "for path, label in paths_and_labels:\n",
    "    process_images(path, label, data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23321e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c11cd80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data to scale pixel values between 0 and 1\n",
    "data = data / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c87f8dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the labels\n",
    "labels = to_categorical(labels, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4db1018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db1580a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ProjectHEAD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define a simple CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')  # 10 output classes for the diseases\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0169495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "247556c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 255ms/step - accuracy: 0.2867 - loss: 1.9597 - val_accuracy: 0.4583 - val_loss: 1.5504\n",
      "Epoch 2/10\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 242ms/step - accuracy: 0.4129 - loss: 1.6397 - val_accuracy: 0.4860 - val_loss: 1.4793\n",
      "Epoch 3/10\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 245ms/step - accuracy: 0.4807 - loss: 1.4535 - val_accuracy: 0.5328 - val_loss: 1.3267\n",
      "Epoch 4/10\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 245ms/step - accuracy: 0.5050 - loss: 1.3919 - val_accuracy: 0.5556 - val_loss: 1.2364\n",
      "Epoch 5/10\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 244ms/step - accuracy: 0.5366 - loss: 1.2869 - val_accuracy: 0.5789 - val_loss: 1.1490\n",
      "Epoch 6/10\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 254ms/step - accuracy: 0.5525 - loss: 1.2438 - val_accuracy: 0.5586 - val_loss: 1.1851\n",
      "Epoch 7/10\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 250ms/step - accuracy: 0.5924 - loss: 1.1359 - val_accuracy: 0.6116 - val_loss: 1.0857\n",
      "Epoch 8/10\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 248ms/step - accuracy: 0.5972 - loss: 1.0942 - val_accuracy: 0.6030 - val_loss: 1.0727\n",
      "Epoch 9/10\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 248ms/step - accuracy: 0.6055 - loss: 1.0670 - val_accuracy: 0.6451 - val_loss: 0.9845\n",
      "Epoch 10/10\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 261ms/step - accuracy: 0.6289 - loss: 1.0081 - val_accuracy: 0.6528 - val_loss: 0.9319\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d0c1766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model after training\n",
    "model.save(\"eye_disease_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a707eeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 - 6s - 60ms/step - accuracy: 0.6528 - loss: 0.9319\n",
      "Test accuracy: 0.6528162360191345\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
